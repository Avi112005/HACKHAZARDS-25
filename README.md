![github-submission-banner](https://github.com/user-attachments/assets/a1493b84-e4e2-456e-a791-ce35ee2bcf2f)

# üöÄ Weave AI magic with Groq

> GroqMate: Your real-time multilingual AI assistant for seamless chatting, coding, image analysis, and voice interaction.

---

## üìå Problem Statement

  
**Problem Statement 1 ‚Äì Weave AI magic with Groq**

---

## üéØ Objective

This project creates a multilingual AI assistant that supports text, audio, and image inputs to serve students, professionals, developers, and those with accessibility needs. By leveraging Groq's AI models, the solution offers:

- Real-time feedback on math problems and learning activities.

- Live audio descriptions for visually impaired users.

- Real-time code analysis and developer productivity tools.

- Health insights and personalized recommendations.

- News summarization for staying updated.

The solution provides personalized assistance and enhanced accessibility, improving efficiency across various use cases.

---

## üß† Team & Approach

### Team Name:  
`Rustrack`

### Team Members:  
- Name 1 (GitHub / LinkedIn / Role)  
- Name 2  
- Name 3  
*(Add links if you want)*

### Your Approach:  
- We chose this problem to bridge the gap between advanced AI technology and everyday users. As the demand for multilingual support and AI-powered assistance grows, we saw an opportunity to create a unified platform that helps users across various domains such as education, health, development, and accessibility.  

- We addressed key challenges such as ensuring the assistant understands and responds accurately in multiple languages, providing real-time processing for tasks like math problems, code analysis, and health insights, designing a vision-based tool for live audio descriptions to help visually impaired users, and integrating multiple AI features‚Äîtext, image, and voice inputs‚Äîinto a seamless experience.

- During development, we faced challenges with real-time speech-to-text accuracy, which we overcame by using Groq's Whisper model for more accurate transcriptions. We also made breakthroughs by integrating image analysis with text and speech, enabling dynamic user interactions. Finally, we brainstormed ways to combine educational, health, and productivity features, ultimately using Groq‚Äôs ultra-fast inference to handle these varied use cases efficiently.

---

## üõ†Ô∏è Tech Stack

### Core Technologies Used:
- Frontend: HTML,CSS,JavaScript
- Backend: Node.js, Express.js
- Database: None (stateless prototype)
- APIs: Groq API (chat, code, STT), Google Gemini Vision API
- Hosting:

### Sponsor Technologies Used (if any):
‚úÖ **Groq:** _How you used Groq_  
- [ ] **Monad:** _Your blockchain implementation_  
- [ ] **Fluvio:** _Real-time data handling_  
- [ ] **Base:** _AgentKit / OnchainKit / Smart Wallet usage_  
- [ ] **Screenpipe:** _Screen-based analytics or workflows_  
- [ ] **Stellar:** _Payments, identity, or token usage_
*(Mark with ‚úÖ if completed)*
---

## ‚ú® Key Features

Highlight the most important features of your project:

‚úÖ Real-time multilingual AI assistant for text, voice, and image-based communication  
‚úÖ Groq-powered educational tutor providing instant math problem feedback through voice and image input  
‚úÖ Vision-based accessibility tool offering live audio descriptions for visually impaired users  
‚úÖ AI-driven code editor with real-time analysis, intelligent suggestions, linting, and auto-generated documentation 

Add images, GIFs, or screenshots if helpful!

---

## üìΩÔ∏è Demo & Deliverables

- **Demo Video Link:** [Paste YouTube or Loom link here]  
- **Pitch Deck / PPT Link:** [Paste Google Slides / PDF link here]  

---

## ‚úÖ Tasks & Bonus Checklist

‚úÖ **All members of the team completed the mandatory task - Followed at least 2 of our social channels and filled the form** (Details in Participant Manual)  
- [ ] **All members of the team completed Bonus Task 1 - Sharing of Badges and filled the form (2 points)**  (Details in Participant Manual)
- [ ] **All members of the team completed Bonus Task 2 - Signing up for Sprint.dev and filled the form (3 points)**  (Details in Participant Manual)

*(Mark with ‚úÖ if completed)*

---

## üß™ How to Run the Project

### Requirements:
- Node.js (v18 or above) is used in this project
- Groq API Key - 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
- Google Gemini API Key - AIzaSyBEUr9cpuup0zV5hSVQkbGEzpXsAzJnw5M

- .env file setup (if needed)
Create a .env file in the root directory with the following:

GROQ_API_KEY= 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
GEMINI_API_KEY= AIzaSyBEUr9cpuup0zV5hSVQkbGEzpXsAzJnw5M



### Local Setup:
```bash
# Clone the repo
git clone https://github.com/Avi112005/HACKHAZARDS-25.git

# Install dependencies
cd HACKHAZARDS-25
npm install

#For manually downloading dependecies
npm install express multer fs cors fluent-ffmpeg groq-sdk dotenv @google/generative-ai

# Start development server
node server.js
```

Provide any backend/frontend split or environment setup notes here.
- Make sure to use Node.js of version 18.0 or above
- In .env simply paste GROQ_API_KEY= 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  GEMINI_API_KEY= AIzaSyBEUr9cpuup0zV5hSVQkbGEzpXsAzJnw5M
 
---

## üß¨ Future Scope

List improvements, extensions, or follow-up features:

- üìà More integrations  
- üõ°Ô∏è Security enhancements  
- üåê Localization / broader accessibility  

---

## üìé Resources / Credits

- APIs or datasets used  
- Open source libraries or tools referenced  
- Acknowledgements  

---

## üèÅ Final Words

Share your hackathon journey ‚Äî challenges, learnings, fun moments, or shout-outs!

---
